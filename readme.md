
# ğŸ¤– CrazyAssistant Chatbot

CrazyAssistant Ã© um chatbot avanÃ§ado com suporte a processamento de documentos, geraÃ§Ã£o de descriÃ§Ãµes de imagens e interaÃ§Ãµes dinÃ¢micas com usuÃ¡rios, utilizando tecnologia de Ãºltima geraÃ§Ã£o. Este projeto usa **LLaMA** para criaÃ§Ã£o de chatbots personalizados, integrando **RAG (Retrieval-Augmented Generation)** com **documentos locais** e serviÃ§os na nuvem.

---

## ğŸ“‹ Ãndice
- [ğŸš€ Funcionalidades](#-funcionalidades)
- [âš™ï¸ Tecnologias](#-tecnologias)
- [ğŸ“¦ Estrutura de DiretÃ³rios](#-estrutura-de-diretÃ³rios)
- [ğŸ’» InstalaÃ§Ã£o](#-instalaÃ§Ã£o)
- [ğŸ“ Como Usar](#-como-usar)
- [ğŸ™‹â€â™€ï¸ ContribuiÃ§Ãµes](#-contribuiÃ§Ãµes)
- [ğŸ” LicenÃ§a](#-licenÃ§a)

---

## ğŸš€ Funcionalidades
- **InteraÃ§Ãµes baseadas em documentos**: O chatbot responde Ã s perguntas com base em arquivos armazenados localmente ou em serviÃ§os como **SharePoint**.
- **DescriÃ§Ã£o de imagens**: GeraÃ§Ã£o automÃ¡tica de descriÃ§Ãµes para imagens usando processamento avanÃ§ado de linguagem natural e OCR.
- **MemÃ³ria de chat personalizada**: O chatbot armazena conversas e permite uma interaÃ§Ã£o contÃ­nua com o usuÃ¡rio, adaptando-se conforme o histÃ³rico.
- **IntegraÃ§Ã£o com LLaMA**: IntegraÃ§Ã£o com o modelo LLaMA para melhorar o desempenho e a qualidade das respostas.
- **PersistÃªncia de dados**: Armazena conversas e Ã­ndices de documentos para consultas futuras.

---

## âš™ï¸ Tecnologias
As principais tecnologias e ferramentas utilizadas no projeto incluem:
- [**LLaMA**](https://github.com/facebookresearch/llama) â€“ Large Language Model para geraÃ§Ã£o de respostas inteligentes.
- **Hugging Face** â€“ Para embeddings de linguagem com o modelo `sentence-transformers/all-mpnet-base-v2`.
- **Ollama** â€“ LLM especializado usado no projeto.
- **Pytesseract** â€“ ExtraÃ§Ã£o de texto em imagens com OCR.
- **BLIP** â€“ GeraÃ§Ã£o de descriÃ§Ãµes de imagens.

---

## ğŸ“¦ Estrutura de DiretÃ³rios

A estrutura do projeto estÃ¡ organizada da seguinte maneira:

```
C:.
â”‚   .gitignore                # Arquivo que especifica quais arquivos e diretÃ³rios devem ser ignorados pelo controle de versÃ£o (Git).
â”‚   config.json               # Arquivo de configuraÃ§Ã£o que armazena informaÃ§Ãµes sensÃ­veis, como credenciais de SharePoint e configuraÃ§Ãµes de projeto.
â”‚   main.py                   # Arquivo principal que contÃ©m o cÃ³digo que orquestra o fluxo do projeto, incluindo o carregamento de documentos, processamento e interaÃ§Ã£o com o chat.
â”‚   readme.md                 # Arquivo de documentaÃ§Ã£o que fornece uma visÃ£o geral do projeto, instruÃ§Ãµes de uso e configuraÃ§Ã£o.
â”‚   requirements.txt          # Lista de dependÃªncias do Python necessÃ¡rias para o projeto, usada para configurar o ambiente com `pip install -r requirements.txt`.
â”‚
â”œâ”€â”€â”€chat-memory               # DiretÃ³rio que armazena a memÃ³ria do chat para diferentes usuÃ¡rios.
â”‚       fulano_memory.json    # Arquivo de memÃ³ria do chat para um usuÃ¡rio especÃ­fico (neste exemplo, "Fulano"), onde sÃ£o armazenadas interaÃ§Ãµes anteriores do chat.
â”‚
â”œâ”€â”€â”€data                      # DiretÃ³rio onde os documentos locais sÃ£o armazenados para processamento.
â”‚                             # SubdiretÃ³rios e arquivos podem ser adicionados aqui para diferentes tipos de documentos (PDF, DOCX, imagens, etc.).
â”‚
â”œâ”€â”€â”€index                     # DiretÃ³rio que armazena os arquivos de Ã­ndice gerados apÃ³s o processamento dos documentos.
â”‚       index.pkl             # Arquivo principal de Ã­ndice usado para buscar e recuperar documentos no chat.
â”‚
â”œâ”€â”€â”€persist-content           # DiretÃ³rio onde sÃ£o armazenados conteÃºdos persistentes, como vetores de embedding e estruturas de documentos.
â”‚       default__vector_store.json  # Armazena vetores de embedding padrÃ£o para a busca vetorial.
â”‚       docstore.json               # Armazena os metadados e informaÃ§Ãµes sobre os documentos processados.
â”‚       graph_store.json            # Armazena a estrutura de grafos entre os documentos, Ãºtil para relacionamentos e consultas complexas.
â”‚       image__vector_store.json    # Vetores de embedding para imagens processadas, caso haja suporte para consultas de imagens.
â”‚       index_store.json            # Armazena a estrutura do Ã­ndice que associa documentos com seus vetores de embedding.
â”‚
â””â”€â”€â”€tools                     # DiretÃ³rio com scripts auxiliares usados para processar documentos, gerenciar Ã­ndices e configurar o chat.
        chat_helpers.py        # Script com funÃ§Ãµes auxiliares para o chat, como configuraÃ§Ã£o e gerenciamento de memÃ³ria.
        document_processing.py # Script que contÃ©m funÃ§Ãµes para processar e preparar documentos para inclusÃ£o no Ã­ndice.
        index_management.py    # Script responsÃ¡vel pela criaÃ§Ã£o e gerenciamento de Ã­ndices de documentos.
        __init__.py            # Arquivo que marca este diretÃ³rio como um pacote Python, permitindo que os mÃ³dulos sejam importados no projeto.

```

---

## ğŸ’» InstalaÃ§Ã£o

Siga os passos abaixo para configurar o ambiente do projeto:

1. **Clone o repositÃ³rio**:
   ```bash
   git clone https://github.com/MarianaMendanha/CrazyAssistant-Chatbot.git
   ```

2. **Instale as dependÃªncias**:
   Certifique-se de ter o **Miniconda** instalado e crie um ambiente:
   ```bash
   conda create --name llama python=3.9
   conda activate llama
   pip install -r requirements.txt
   ```

3. **Configure o Tesseract**:
   Baixe e instale o [Tesseract OCR](https://github.com/tesseract-ocr/tesseract) e ajuste o caminho no cÃ³digo.


4. **Instale os Drivers da NVIDIA:**
   - Baixe e instale os drivers NVIDIA mais recentes para sua GPU. Isso Ã© essencial para garantir que o CUDA e outros componentes funcionem corretamente.
   - **Tutorial:** [Como Instalar os Drivers NVIDIA](https://www.youtube.com/watch?v=r7Am-ZGMef8)


5. **Instale o Ollama:**
   - Baixe e instale o Ollama para criar e gerenciar seus LLMs.
   - **Tutorial:** [InstalaÃ§Ã£o do Ollama](https://github.com/ollama/ollama)
   - ApÃ³s instalar o Ollama, faÃ§a o pull do modelo LLM que vocÃª deseja usar.

5. **Instale a VersÃ£o Correta do PyTorch:**
   - Baixe e instale a versÃ£o do PyTorch compatÃ­vel com a versÃ£o do CUDA e drivers da NVIDIA que vocÃª instalou.
   - **Tutorial:** [InstalaÃ§Ã£o do PyTorch](https://pytorch.org/get-started/locally/)

Siga esses passos para garantir que todos os componentes estejam corretamente configurados para o funcionamento adequado do projeto.

---

## ğŸ“ Como Usar

1. **Iniciar o chatbot**:
   Execute o script principal:
   ```bash
   python main.py
   ```

2. **Carregue seus documentos**:
   - Coloque seus arquivos na pasta `data`.

3. **Interaja com o chatbot**:
   - ApÃ³s carregar os documentos, vocÃª pode fazer perguntas ao chatbot sobre eles.
   - O chatbot responde com base no conteÃºdo dos documentos.

4. **PersistÃªncia da Conversa**:
   - O histÃ³rico da conversa Ã© salvo na pasta `chat-memory`, permitindo que a interaÃ§Ã£o continue em sessÃµes futuras.

---

## ğŸ™‹â€â™€ï¸ ContribuiÃ§Ãµes

ContribuiÃ§Ãµes sÃ£o bem-vindas! Sinta-se Ã  vontade para abrir issues e enviar pull requests. Aqui estÃ¡ como vocÃª pode contribuir:

1. **Fork o repositÃ³rio**.
2. **Crie uma branch para sua feature** (`git checkout -b feature/nome-da-feature`).
3. **FaÃ§a o commit de suas alteraÃ§Ãµes** (`git commit -m 'Adiciona nova feature'`).
4. **FaÃ§a o push para a branch** (`git push origin feature/nome-da-feature`).
5. **Abra um Pull Request**.

---

## ğŸ” LicenÃ§a
